### Day1 (2025.12.22)

- 初始化项目结构 
- 对接 DeepSeek API
- 数据整理, 放入 SQLite 数据库
- [思考] 新闻数据是纯 html 无法直接用统计学方法进行文本分析, 如果先清理再处理会耗费大量时间, 在这里可以直接利用大模型进行信息抽取, 分成三个指

总结: 

- 已经完成初步的数据处理

### Day2 (2025.12.23)

- 接下来要做的
    - 先做一个可视化决策面板, 来获取数据的全貌
    - 实现 trading agent 完成基本 pipeline
    - 回测引擎
    - 对比实验
    - 微调

- 突然想到 情绪分析这一块应该用更严谨的方式来回测 而不是直接用 prompt
- nof1.ai 很好的证明了光靠 LLM 的 Trading Agent 是不可靠的, 必须有足够的 reasoning 防止大模型幻觉
- 遇到了一个问题, 发现数据其实有很多缺失

解决方案: 保证 features table 的完整性

- [思考] 考虑未来用 column based database 来存储因子?

- 现在代码有点多, 适合重构

- 在仅一周周期且缺乏人工标注数据集的前提下, 进行参数级微调（SFT / RLHF / PEFT）在工程和方法论上都不合理
- 考虑 LLM Agent 接口尚未确定, 先做一个 Naive 
- 发现数据量实在太少了, 基本无法有效训练
- 根据试验 `1.2` 可以看出来普通的策略在上涨大盘中倾向于持有, 这么说在多持仓模型下如何调配持仓变得更加重要了
- 本来想用一个追涨杀跌的策略来测试风险控制模块, 结果发现它是赚的最多的, 当然它在各类风险指标它也是最危险的

---

总结: 

- 做了一些代码结构上的优化, 项目框架基本成型, 测试了一些朴素策略, 多持仓 Agent 结果不尽人如意

- 优化方向 (LLM Agent 思路)
    - 之后的研究主要专注单股票策略, 利用别的股票的信息交叉验证
    - 用其中 10 支股票训练一个 predict 模型 (例如 LSTM) 先进行测试作为 baseline
    - 接着在原本的 predict 模型上融合大模型来修正决策, 类似 LLM 增强框架
    - 绘制系统结构图
    - 起草 REPORT
    - 增加 agent 横向对比

### Day3

- 今天训练 LSTM 不出意外的几乎没有预测能力, 但是不妨碍在上面使用 LLM 增强框架
- 完成了 Cited-RAG 的构建
- 在原本的, 测试将原本的裸 LLM 模块改成 RAG 模块, 测试性能提升

---

总结:

尝试直接用 RAG 来做一个简单的问答 Agent 但是觉得技术路线有问题 实在不太行, 因为没有用 LLM 做 Agent 的经验, 还是需要调研一下

### Day 4

- 中午开始研究如何用 LLM 做 Agent
    - 新闻驱动: 通过新闻信号来做判断
    - *Reflection-driven: 通过错误 来自我纠错
    - Debate Driven: 多头分析师, 空头分析师, 风控官 
      解读: 感觉有点类似 multi agent
    - RL-driven
      实现难度太高了, 但是 state, action 的思路依旧可以参考
